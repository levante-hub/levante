{
  "title": "Models",
  "provider_config": {
    "title": "Provider Configuration",
    "description": "Select and configure your AI provider",
    "active_provider": "Active Provider",
    "select_provider": "Select a provider",
    "configured": "Configured"
  },
  "provider_types": {
    "openrouter": "Access to 100+ AI models through OpenRouter API",
    "vercel_gateway": "Vercel AI Gateway for unified model access",
    "local": "Local AI models (Ollama, LM Studio, etc.)",
    "openai": "Direct integration with OpenAI GPT models",
    "anthropic": "Direct integration with Anthropic Claude models",
    "google": "Direct integration with Google Gemini models",
    "groq": "Ultra-fast inference with Groq LPUâ„¢ Inference Engine",
    "xai": "Access to Grok models from xAI"
  },
  "api_key": {
    "label": "API Key",
    "optional": "API key is optional for model listing but required for inference",
    "get_key": "Get your key"
  },
  "oauth": {
    "sign_in": "Sign in with OpenRouter",
    "waiting": "Waiting for authorization...",
    "connect_message": "Connect your account securely with one click"
  },
  "base_url": {
    "label": "Base URL",
    "help_gateway": "Configure your Vercel AI Gateway at",
    "help_local": "Default ports: Ollama (11434), LM Studio (1234), LocalAI (8080)"
  },
  "organization_id": {
    "label": "Organization ID (Optional)",
    "description": "For users in multiple organizations"
  },
  "models": {
    "title": "Available Models",
    "from": "Models from {{provider}}",
    "sync": "Sync Models",
    "sync_now": "Sync Models Now",
    "discover": "Discover Models",
    "select_all": "Select All",
    "deselect_all": "Deselect All",
    "selected": "Selected: {{count}} of {{total}} models",
    "only_selected": "Only selected models appear in chat",
    "no_models": "No models available",
    "sync_prompt": "Click \"Sync Models\" to load available models from the provider",
    "configure_key": "Configure your API key above to sync models",
    "user_defined": "This provider uses user-defined models. Add models manually",
    "search_placeholder": "Search models by name...",
    "no_search_results": "No models found matching \"{{query}}\"",
    "selected_section": "Selected Models ({{count}})",
    "selected_description": "These models appear in chat",
    "available_section": "Available Models ({{count}})",
    "available_description": "Select to use in chat",
    "no_models_configured": "No models available. Configure your provider and sync models"
  },
  "model_info": {
    "context_length": "Context Length: {{length}} tokens",
    "pricing": "Pricing: ${{input}}/M input, ${{output}}/M output",
    "capabilities": "Capabilities"
  },
  "stats": {
    "available": "Models available: {{count}}",
    "source": "Model source: {{source}}",
    "source_dynamic": "Fetched automatically",
    "source_user": "User-defined",
    "last_sync": "Last sync: {{date}}",
    "active": "Active",
    "select_message": "Please select a provider above to configure",
    "save": "Save"
  },
  "links": {
    "vercel_dashboard": "Vercel Dashboard"
  },
  "free_model_warning": {
    "title": "Free Model Privacy Notice",
    "description_1": "When you use a free model on OpenRouter, your prompts and completions may be shared with the provider team and published to public datasets.",
    "description_2": "If you're comfortable with this, you need to enable this in your OpenRouter privacy settings:",
    "required_settings": "Required settings:",
    "setting_1": "Enable free endpoints that may publish prompts",
    "setting_2": "Allow free model providers to publish your prompts and completions to public datasets",
    "cancel": "Cancel",
    "privacy_settings": "Privacy Settings",
    "continue": "Continue"
  }
}
